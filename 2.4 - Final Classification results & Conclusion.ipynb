{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPir0I1aIGe3y/ikRrGuei6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"x5lbBeLY7qnn"},"source":["# FINAL METRICS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1734613329296,"user":{"displayName":"Patricia “Trisha” Martinez","userId":"17780423676423305166"},"user_tz":-60},"id":"KwttKLdf7spJ","outputId":"68bd8ca4-f31f-40ca-d8ba-79a09fd79f7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["                       Model  Accuracy  Precision  Recall  F1 Score  \\\n","0        Logistic Regression     0.695   0.705381   0.695  0.693464   \n","1                        KNN     0.570   0.574997   0.570  0.540759   \n","2              Decision Tree     0.985   0.984809   0.985  0.984825   \n","3                Naive Bayes     0.820   0.830405   0.820  0.822853   \n","4              Random Forest     0.985   0.985455   0.985  0.984434   \n","5                    XGBoost     0.995   0.995094   0.995  0.995011   \n","6  Logistic Regressión Tuned     0.705   0.720543   0.705  0.695091   \n","7                  KNN Tuned     0.665   0.677768   0.665  0.640641   \n","8          Naive Bayes Tuned     0.820   0.830405   0.820  0.822853   \n","\n","   Cross Validation Score  \n","0                0.693333  \n","1                0.568750  \n","2                0.995833  \n","3                0.775000  \n","4                0.984583  \n","5                0.993750  \n","6                0.693333  \n","7                0.643750  \n","8                0.775000  \n"]}],"source":["collect_metrics(metrics)"]},{"cell_type":"markdown","metadata":{"id":"W5LmQeuwyM6W"},"source":["There is not that much of an improvement in the tuned models."]},{"cell_type":"markdown","metadata":{"id":"gsd3nsBr3BCG"},"source":["# Final Conclusion:\n","Data does not improve with parameter tuning so those models are discarded for this dataset.\n","\n","I acknowledge I did a lot of graphs and a lot of analyzing, I wanted to make sure every posibility was taking into account and showcase the way I work.\n","\n","The most accurate models for this data are:\n","- Decission Tree\n","- XGBoost\n","- Random Forest\n","\n","Kmeans is the worst option for this data, but this happens because of the nature of the data, as seen in the EDA graphs the data in most variables is quite dispersed, but I tried to analyze if there was really a pattern or not and there is none.  \n","\n","Analyzing the errors from the parameter tuned models, I can say:\n","- They may not work because the target I chose is multiclass. This models work better with binary target classification.\n","- This models may be too simple for a dataset where more complex models only needed 3 variables to obtain great results.\n","- Analyzing the feature importances of the simpler models and comparing them to the feature importances of the other 3 models, there is a logic. The \"best 3\" have chosen the same variables to predict giving almost none importance to the rest. The \"worst 3\" (4 if we take into account the Kmeans) have tried to give some importance value to many more independent features, so the relation between the variables that really means something gets distorted and errors occur. \"It just to happens\" the features the \"best 3\" models gave the importance to, are the ones we saw in the EDA and with the Anova table had the most relevance."]}]}